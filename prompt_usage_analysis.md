# 半导体QA生成系统 - Prompt使用梳理文档

## 系统概述

半导体显示技术领域智能QA生成系统包含完整的**三步评估流程**：
1. **文本质量评估** - 判断文本是否适合生成逻辑推理问题
2. **问题生成** - 基于高质量文本生成技术问题
3. **问题质量评估** - 评估生成的问题是否符合推理问题标准

---

## 第一阶段：文本质量评估

### 阶段目标
判断输入的学术论文文本是否适合生成复杂的逻辑推理问题。

### 调用的Prompt模板
**模板名称**: `score_template`

**模板内容**:
```
你的任务是依据以下评分规则对文本质量进行打分，并输出最终得分。评分流程如下：

首先，请仔细阅读给定的文本内容，然后根据以下4个标准逐一进行评分：

1. 标准1：文本完整性
(1) 文本严重缺失、不完整或存在大量乱码，得 -1 分。
(2) 文本基本完整但存在少量缺失或错误，得 +0.5 分。
(3) 文本完整且结构清晰，得 +1 分。

2. 标准2：语言表达
(1) 文本语言混乱、表达不清，难以理解，得 -1 分。
(2) 文本语言基本清晰，表达较为准确，得 +0.5 分。
(3) 文本语言规范、表达精确，逻辑清晰，得 +1 分。

3. 标准3：技术内容
(1) 文本技术内容空洞或错误明显，得 -1 分。
(2) 文本技术内容基本正确但深度不够，得 +0.5 分。
(3) 文本技术内容丰富且准确，具有一定技术深度，得 +1 分。
(4) 文本技术内容深入且具有创新性见解，得 +1 分。
(5) 文本技术卓越正确，解释严格精确（如形式化证明、精确计算），得 +1 分。

4. 标准4：思维和推理
(1) 文本无任何思维或推理迹象，得 -1 分。
(2) 文本展现一些基本思维和推理能力（如直接应用已知技术、简单分析问题），得 +0.5 分。
(3) 文本展现一定思维和推理能力（如考虑多种解决方法、讨论不同方案权衡），得 +0.5 分。
(4) 文本展现显著思维和推理能力（如通过多步推理链解决复杂问题、运用专业科学领域高级推理模式），得 +1 分。
(5) 文本展现卓越思维和推理能力（如以高度创新方式解决专业领域复杂问题、结合多种推理技术对问题进行新抽象），得 +1 分。

最终评判标准：若各项标准得分均大于零，且标准4得分大于等于1分，则该文本内容适合生成逻辑推理问题。

[文本内容的开始]
{academic_paper}
[文本内容的结束]

格式要求：只输出文本内容是否适合生成复杂推理问题，不输出任何别的内容。并且是否适合严格按照以下格式进行输出：
【是】或者【否】。不要输出为空，不要输出其他内容，输出是或否时，要带上【】符号进行输出。
```

### 调用方法
- **函数**: `judge_md_data()`
- **实现位置**: 第780行开始
- **使用方式**: 
  ```python
  score_prompt = self.score_template.replace("{academic_paper}", paper_content)
  score_messages = [
      {"role": "system", "content": "你是一个乐于助人的半导体显示技术领域的专家。"},
      {"role": "user", "content": score_prompt}
  ]
  ```

### 输出格式
- **成功**: `【是】`
- **失败**: `【否】`

---

## 第二阶段：问题生成

### 阶段目标
基于通过第一阶段质量评估的文本，生成3个需要逻辑推理才能解答的高质量技术问题。

### 调用的Prompt模板
**模板名称**: `prompt_template`

**模板内容**:
```
你是一位半导体显示技术领域的资深专家，擅长从技术文献中提炼核心知识点。你的职责是从论文中生成问题和相应的答案，问题和相应的答案对需要提供给资深的人员学习，问题和相应的答案的质量要高。请根据输入的学术论文内容，生成3个需要逻辑推理才能解答的高质量技术问题，请确保这些问题能够直接从论文中找到答案。这些问题将用于资深研究人员的专业能力评估，需满足以下要求：

<think>
首先，我需要仔细阅读这篇学术论文，理解其核心内容和技术要点。

让我分析论文的主要内容：
1. 识别论文讨论的核心技术问题
2. 找出涉及逻辑推理的技术原理和机制
3. 确定可以设计深度问题的关键点

接下来，我将基于以下原则设计问题：
- 问题必须基于论文内容，答案可以从论文中找到
- 问题需要逻辑推理才能解答，不能是简单的事实性问题
- 问题描述要清晰、完整、专业
- 避免使用"本文"、"论文"等自指表述
- 确保问题具有技术深度和挑战性
</think>

##【核心要求】
### 问题设计准则：
(1) 仔细通读全文，找出涉及逻辑推理的文本部分，据此设计相关问题。
(2) 问题要基于论文里的技术原理，描述务必清晰、全面、明确。问题中主语或名词的表述要精准、全面且通用。
(3) 避免在问题中引用文献或文章自定义的专有名词。利用自身半导体显示领域知识，生成通用问题，确保不读论文也能理解问题含义。
(4) 问题中的名词描述必须和论文一致，不能缩写。比如论文是"OLED材料"，问题不能写成"材料"；论文是"LTPS器件"，问题不能写成"器件"。
(5) 提问不能针对论文里的某个特定示例。要让顶尖科学家不读论文也能理解并回答问题。问题里不能有"书本""论文""本文""本实验"等类似表述。
(6) 确保生成问题完整，与论文彻底解耦，不依赖论文内容。若问题有背景信息，必须阐述清楚。
(7) 问题简洁：生成的问题要凝练、简洁。

### 问题设计的科学严谨性：
(1) 因果链：问题需呈现完整技术逻辑链，比如"机制A怎样影响参数B，进而引发现象C"。
(2) 周密性：思考过程要科学严谨，逐步推进。保证问题及对应答案源自论文内容，且答案在论文中有详细阐述。

## 【禁止事项】
× 禁止使用"本文/本研究/本实验"等论文自指表述
× 禁止提问孤立概念（如：XX技术的定义是什么）
× 禁止超出论文技术范围的假设性问题

##【格式要求】
用中文输出。当前阶段只设计问题，不输出答案。输出问题前必须用 </think> 结束思考后在输出问题。严格按照以下格式输出你设计的问题：
[[1]] 第1个问题
[[2]] 第2个问题
[[3]] 第3个问题

[学术论文的开始]
{academic_paper}
[学术论文的结束]
```

### 调用方法
- **函数**: `generate_question_data()`
- **实现位置**: 第1095行开始
- **使用方式**: 
  ```python
  # 基础使用
  generate_prompt = self.prompt_template.replace("{academic_paper}", paper_content)
  
  # 带额外提示的使用
  if add_prompt:
      enhanced_template = self.prompt_template.replace(
          "### 输出格式要求：",
          f"{add_prompt}\n\n### 输出格式要求："
      )
      generate_prompt = enhanced_template.replace("{academic_paper}", paper_content)
  
  messages = [
      {"role": "system", "content": "你是一个乐于助人的半导体显示技术领域的专家。"},
      {"role": "user", "content": generate_prompt}
  ]
  ```

### 输出格式
```
[[1]] 问题1的内容
[[2]] 问题2的内容  
[[3]] 问题3的内容
```

---

## 第三阶段：问题质量评估

### 阶段目标
评估第二阶段生成的问题是否符合推理问题标准，确保问题质量。

### 调用的Prompt模板
**模板名称**: `evaluator_template`

**模板内容**:
```
您是一位专家评估员，负责决定问题是否符合推理问题标准。您的评估必须结合给定文章内容和给定问题判断。

## 【评估标准】
### 因果性：
(1) 问题应展现出完整的技术逻辑链。比如，类似"机制A怎样影响参数B，最终致使现象C出现"这种形式。

### 周密性：
(1) 思维过程要科学且严谨，需逐步思考。问题及对应的答案必须源于论文内容，且答案在论文中要有详细描述。

### 完整性：
(1) 问题是否全面涵盖文章相关内容的各个方面？
(2) 问题描述应简洁凝练，语义完整。
(3) 问题要与文章内容完全独立，不依赖文章也能被清晰理解，即问题需完整、自足。

[文章内容的开始]
{academic_paper}
[文章内容的结束]

[问题内容]
{academic_question}

格式要求：仅输出文本内容生成的问题是否符合标准，严格按以下格式，有且仅输出【是】或者【否】，不输出任何别的内容，不能输出为空，输出是或否时，要带上【】符号进行输出。用中文输出，严格按照以下格式进行输出：【是】或者【否】
```

### 调用方法
- **函数**: `judge_question_data()`
- **实现位置**: 第1459行开始
- **使用方式**: 
  ```python
  evaluator_prompt = self.evaluator_template.replace(
      "{academic_paper}", paper_content
  ).replace(
      "{academic_question}", question_li
  )
  
  evaluator_messages = [
      {"role": "system", "content": "你是一个乐于助人的半导体显示技术领域的专家。"},
      {"role": "user", "content": evaluator_prompt}
  ]
  ```

### 输出格式
- **通过**: `【是】`
- **不通过**: `【否】`

---

## 其他相关模板

### 答案生成模板
在`generate_answers()`方法中使用，有两种模式：

#### COT模式 (use_cot=True)
```
你是一名半导体显示领域的专家，你需要回答的问题是：{question}

请基于以下学术论文内容进行回答：
{paper_content}

请使用以下格式回答：

<Reasoning>:
[在这里进行详细的推理过程，解释你是如何从论文中找到答案的，包括相关的技术原理、因果关系等]

<ANSWER>:
[在这里给出最终答案，要求简洁明确]
```

#### 直接回答模式 (use_cot=False)  
```json
{
    "question": "{question}",
    "paper_content": "{paper_content}",
    "instruction": "请根据给定的学术论文内容回答问题。答案应该基于论文中的具体内容，要求准确、简洁。如果论文中没有相关信息，请回答'无法作答'。"
}
```

---

## 系统流程总结

1. **第一阶段** (`judge_md_data`) → 使用 `score_template` → 输出 `【是】/【否】`
2. **第二阶段** (`generate_question_data`) → 使用 `prompt_template` → 输出问题列表
3. **第三阶段** (`judge_question_data`) → 使用 `evaluator_template` → 输出 `【是】/【否】`
4. **答案生成** (`generate_answers`) → 使用答案生成模板 → 输出答案

每个阶段都有明确的输入输出格式和质量控制机制，确保整个QA生成流程的质量和一致性。